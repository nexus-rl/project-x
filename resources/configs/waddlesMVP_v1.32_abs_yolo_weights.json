{
  "device": "cuda:0",
  "seed": 123,
  "log_to_wandb": true,
  "env_id": "Rocket League",
  "agent": {"type" : "marl"},

  "value_estimator":
  {
    "type" : ["ff", "continuous"],
    "init_type": "normc",
    "init_std" : 1.4,
    "action_init_std": 1.0,
    "action_noise_std" : 0.0,
    "observation_clip_range" : null,
    "normalize_observations" : false,
    "action_parser" : "linear",

    "layers" :
    {
      "ff1":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff2":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff3":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff4":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "output" :
      {
        "type": "output",
        "activation_function" : "linear",
        "extra" : null
      }
    }
  },

  "policy":
  {
    "type" : ["ff", "discrete"],
    "init_type": "normc",
    "init_std": 1.0,
    "action_init_std": 1.0,
    "observation_clip_range": null,
    "normalize_observations": false,
    "layers":
    {
      "ff1":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff2":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff3":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff4":
      {
        "type" : "ff",
        "num_nodes" : 351,
        "activation_function" : "selu",
        "extra" : null
      },
      "output":
      {
          "type": "out",
          "extra": [3,3,3,3,3,2,2,2],
          "num_nodes": 21,
          "activation_function": "softmax"
      }
    }
  },

  "policy_gradient_optimizer":
  {
    "type": "torch adam",
    "step_size": 1e-4
  },

  // not used at the moment
  "novelty_gradient_optimizer":
  {
    "type": "dsgd",
    "step_size": 3e-4
  },

  "value_gradient_optimizer":
  {
    "type": "torch adam",
    "lr": 1e-4
  },

  "policy_optimizer":
  {
    "type": "pg",
    "gamma": 0.995,
    "max_kl": 1.0,
    "n_epochs": 10,
    "batch_size": 100000, // no minibatches, so must fit in VRAM
    "clip_range": 0.2,
    "gae_lambda": 0.98, // should be slightly smaller than gamma
    "entropy_coef": 0.003,
    "max_timesteps": 1e16,
    "eps_per_eval": 5,
    /**
     * Percentage of returns that needs to be "fresh" prior to an update
     * occurring
     */
    "new_returns_proportion": 0.05, 
    "value_updates_per_batch": 10
  },

  "adaptive_omega":
  {
    "mean_threshold": 1.035,
    "reward_history_size": 40,
    "min_value": 0.0,
    "max_value": 1,
    "default": 0.0
  },

  "experience_replay":
  {
    "max_buffer_size": 400000
  },

  "strategy":
  {
    "max_history_size": 200,
    "num_frames": 200,
    "steps_per_eval" : 1,
    "num_fd_perturbations" : 250,
    "fd_noise_std" : 0.1
  },

  "rlgym": {
    "tick_skip": 8,
    "team_size": 2,
    "game_speed": 100,
    "self_play": true,
    "spawn_opponents": true,
    "action_parser": "necto",
    "obs_builder": {
      "absolute_unit_obs" : {
        "pad_teams_to": 3
      }
    },
    "state_setter": "default",
    "rewards": {
      "log_combined": {
        "rewards": [
          "velocity_player_to_ball",
          "velocity_ball_to_goal",
          {
            "log_touch_height": {
              "exp": 0.66
              // "min_height": 250
            }
          },
          {
            "log_event": {
              "goal": 80.0,
              "concede": -80.0,
              "team_goal": 40.0,
              // "touch": 0.3,
              "shot": 5.0,
              "save": 20.0,
              "demo": 20.0,
              "boost_pickup": 0.02
            }
          }
        ],
        "weights":[
          0.1,
          1.0,
          5.0,
          1.0
        ]
      }
    },
    "terminal_conditions": {
      "timeout": {
        "max_steps": 4500 // 5 minutes @ 15 steps/sec
      },
      "no_touch_timeout": {
        "max_steps": 450 
      },
      "goal_scored": {}
    }
  },

  "extra_log": { 
    "rounds_per_aggregate": 120,    // Right now, aggregation step is in MARLAgent, right before experience send
                                   // wait N rounds before aggregating log values and sending
    "log_to_csv": false,
    "wandb_via_redis": true,
    "values": {
      "VelocityBallToGoalReward": { "agg": "rms" },
      "VelocityPlayerToBallReward": { "agg": "rms" },
      "LogTouchHeightReward": { },
      "LogEventReward": { "agg": "rms" },
      "touch": { "agg": "mean_per", "per": "steps" }, 
      "boost_pickup": { "agg": "mean_per", "per": "steps" },
      "goal": { "agg": "mean_per", "per": "steps" }, 
      "shot": { "agg": "mean_per", "per": "steps" }, 
      "save": { "agg": "mean_per", "per": "steps" }, 
      "demo": { "agg": "mean_per", "per": "steps" }, 
      "ball_speed": { },   
      "ball_height": { }, 
      "car_speed": { }, 
      "car_height": { }, 
      "touch_grass": { }, 
      "boost_held": { }, 
      "dist_to_ball": { }, 
      "speed_to_ball": { },
      "face_ball": { },
      "ball_goal_align": { },
      "TouchHeight": { "agg": "mean_per", "per": "steps" },
      "TouchHeight_norm_height": { }
    }
  },

  "lr_adjuster":
  {
    "clip_target": 0.1,
    "rate": 1.1,
    "max_lr": 1,
    "min_lr": 1e-7
  }
}
